{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "import subprocess\n",
    "import uuid\n",
    "import csv\n",
    "import json\n",
    "import hashlib\n",
    "import os\n",
    "import shutil\n",
    "import urllib3\n",
    "from urllib.parse import quote"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Read the Config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('config/config.json', 'r') as infile:\n",
    "    config = json.load(infile)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('config/exportMetadata.v2.json', 'r') as infile:\n",
    "    exportMetadata = json.load(infile)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('config/Default.Project.json', 'r') as infile:\n",
    "    defaultProject = json.load(infile)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Read the plans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read the execution plans\n",
    "dfPlans = pd.read_csv('in/plans.csv', dtype='str', encoding='utf-8', na_filter=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO remove below testing filter\n",
    "#dfPlans = dfPlans.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get a list of unique execution plans\n",
    "plans = dfPlans['plan_name'].unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Lookup the Converted Mapping Task IDs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Login to IDMC\n",
    "http = urllib3.PoolManager()\n",
    "\n",
    "data = '{ \"username\": \"' + config['idmc']['user'] + '\", \"password\": \"' + config['idmc']['password'] + '\" }'\n",
    "\n",
    "url = 'https://' + config['idmc']['host'] + '/saas/public/core/v3/login'\n",
    "r = http.request(\n",
    "    'POST', \n",
    "    url,\n",
    "    timeout=3000,\n",
    "    body=data,\n",
    "    headers={\n",
    "            'Accept': 'application/json',\n",
    "            'Content-Type': 'application/json'\n",
    "        }\n",
    "    )\n",
    "    \n",
    "# Convert the response into a datframe\n",
    "result = json.loads(r.data.decode('utf-8'))\n",
    "sessionID = result['userInfo']['sessionId']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialise the tasks data frame\n",
    "skip = 0\n",
    "limit = 200\n",
    "i = 0\n",
    "dfTasks = pd.DataFrame()\n",
    "\n",
    "# Page through mapping task queries\n",
    "while True:\n",
    "\n",
    "    # Get a list of the mapping tasks\n",
    "    url = 'https://' + config['idmc']['pod'] + '.' + config['idmc']['host'] + '/saas/public/core/v3/objects?q=type==%27MTT%27&limit=' + str(limit) + '&skip=' + str(skip)\n",
    "    r = http.request(\n",
    "        'GET', \n",
    "        url,\n",
    "        timeout=3000,\n",
    "        headers={\n",
    "                'Accept': 'application/json',\n",
    "                'INFA-SESSION-ID': sessionID\n",
    "            }\n",
    "        )\n",
    "        \n",
    "    # Convert the response into a datframe\n",
    "    result = json.loads(r.data.decode('utf-8'))\n",
    "    dfTmp = pd.json_normalize(result)\n",
    "    dfResp = dfTmp.copy()\n",
    "    taskCount = dfResp.iloc[0]['count']\n",
    "    dfResp = dfResp['objects'].explode()\n",
    "    dfResp = pd.DataFrame(dfResp)\n",
    "    dfResp = pd.json_normalize(dfResp['objects'])\n",
    "    dfTasks = pd.concat([dfTasks, dfResp], ignore_index=True)\n",
    "\n",
    "    # Break if all records have been returned\n",
    "    i = i + limit\n",
    "    if i > taskCount:\n",
    "        break\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Join the task id's onto the plans\n",
    "dfResp['step_name'] = dfResp['path'].apply(lambda x: os.path.basename(x))\n",
    "dfResp = dfResp[['step_name','id','path']]\n",
    "dfResp = dfResp.rename(columns={'id': 'infa_id', 'path': 'infa_path'})\n",
    "dfPlans = dfPlans.merge(dfResp, how='left', on='step_name')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Log an error if any plans did not find an existing matching task\n",
    "dfMissing = dfPlans[(dfPlans['infa_id'] == '') | (dfPlans['infa_id'].isna())].copy()\n",
    "if len(dfMissing.index) > 0:\n",
    "    dfMissing.to_csv('out/missing_tasks.csv', index=False, quoting=csv.QUOTE_ALL)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create the Import Packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For each unique plan\n",
    "for plan in plans:\n",
    "    \n",
    "    # Create IDs and a clean version of the name for the new taskflow\n",
    "    tName = re.sub(r'[^\\w\\d]+', '_', plan)\n",
    "    \n",
    "    # Reset the output directories\n",
    "    if os.path.exists(f'out/{tName}'):\n",
    "        shutil.rmtree(f'out/{tName}')\n",
    "    os.makedirs(f\"out/{tName}/Explore/Default\")\n",
    "    \n",
    "    # Generate the unique IDs\n",
    "    projectID = str(uuid.uuid4()).replace('-','')\n",
    "    taskflowID = str(uuid.uuid4()).replace('-','')\n",
    "\n",
    "    # Create the ContentsofExportPackage File\n",
    "    content = {'objectPath': ['/Explore/Default','/Explore'], 'objectName': [tName, 'Default'], 'objectType': ['TASKFLOW', 'Project'], 'id': [taskflowID, projectID]}\n",
    "    contentDf = pd.DataFrame(data=content)\n",
    "    contentDf.to_csv(f'out/{tName}/ContentsofExportPackage_{tName}.csv', index=False, quoting=csv.QUOTE_NONE)\n",
    "\n",
    "    # Create the exportMetadata file\n",
    "    exportMetadata['name'] = tName\n",
    "    objList = []\n",
    "    taskflowObj = list(filter(lambda x: x['objectType'] == 'TASKFLOW', exportMetadata['exportedObjects']))[0].copy()\n",
    "    taskflowObj['objectGuid'] = taskflowID\n",
    "    taskflowObj['objectName'] = tName\n",
    "    taskflowObj['metadata']['objectRefs'] = dfPlans['infa_id'].to_list()\n",
    "    objList.append(taskflowObj)\n",
    "    \n",
    "    projectObj = list(filter(lambda x: x['objectType'] == 'Project', exportMetadata['exportedObjects']))[0].copy()\n",
    "    projectObj['objectGuid'] = projectID\n",
    "    objList.append(projectObj)\n",
    "    \n",
    "    for index, row in dfPlans.iterrows():\n",
    "        mappingObj = list(filter(lambda x: x['objectType'] == 'MTT', exportMetadata['exportedObjects']))[0].copy()\n",
    "        mappingObj['objectGuid'] = row['infa_id']\n",
    "        mappingObj['objectName'] = row['step_name']\n",
    "        objList.append(mappingObj)\n",
    "    \n",
    "    exportMetadata['exportedObjects'] = objList\n",
    "    \n",
    "    with open(f'out/{tName}/exportMetadata.v2.json', 'w') as outfile:\n",
    "        outfile.write(json.dumps(exportMetadata))\n",
    "\n",
    "    # Create the Default.Project.json file\n",
    "    defaultProject['id'] = f'Projects({projectID})'\n",
    "    with open(f'out/{tName}/Explore/Default.Project.json', 'w') as outfile:\n",
    "        outfile.write(json.dumps(defaultProject))\n",
    "\n",
    "    # Create the taskflow XML file\n",
    "    dfPlans.to_xml('in/plans.xml', index=False, row_name='row')\n",
    "    console = subprocess.run([\"java\", \"-Xmx14000M\", \"-cp\", \"../saxon-he-10.5.jar\", \"net.sf.saxon.Query\", \"-q:convert.xq\", f\"-o:out/{tName}/Explore/Default/{tName}.TASKFLOW.xml\", f\"tname={tName}\", f\"tflowid={taskflowID}\"], capture_output=True)\n",
    "    \n",
    "    # Create the exportPackage.chksum file\n",
    "    with open(f'out/{tName}/Explore/Default.Project.json', 'rb') as infile:\n",
    "        infileBytes = infile.read()\n",
    "        defaultProjectJsonHash = hashlib.sha256(infileBytes).hexdigest().upper()\n",
    "\n",
    "    with open(f'out/{tName}/exportMetadata.v2.json', 'rb') as infile:\n",
    "        infileBytes = infile.read()\n",
    "        exportMetadataHash = hashlib.sha256(infileBytes).hexdigest().upper()\n",
    "\n",
    "    with open(f'out/{tName}/Explore/Default/{tName}.TASKFLOW.xml', 'rb') as infile:\n",
    "        infileBytes = infile.read()\n",
    "        taskflowHash = hashlib.sha256(infileBytes).hexdigest().upper()\n",
    "    \n",
    "    lines = ['#\\n', '#Fri Dec 01 22:59:59 UTC 2023\\n', f'Explore/Default.Project.json={defaultProjectJsonHash}\\n', f'exportMetadata.v2.json={exportMetadataHash}\\n', f'Explore/Default/{tName}.TASKFLOW.xml={taskflowHash}\\n']\n",
    "    with open(f'out/{tName}/exportPackage.chksum', 'w') as outfile:\n",
    "        outfile.writelines(lines)\n",
    "\n",
    "    # Create the import zip file\n",
    "    shutil.make_archive(f'out/{tName}', 'zip', os.path.join('out',tName))\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TEMP BELOW:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['a0Ks8uNXYKLg38LRNzw6gv',\n",
       " '8gORkCCxfM8hk1VxABRRqd',\n",
       " '6vPlMGJ7sw6juVvUtKpxYq',\n",
       " '7PjDO1zxryekytQ7Oh1zEP',\n",
       " 'aeOQ6VugmCxipbYyKlDRUr',\n",
       " 'bspgWgKqNAAkdFCD8X1EGw',\n",
       " '980nZ1ZyECqlJELIoT6seu',\n",
       " '48EkOr6iGA3jPFoSNlYhmt',\n",
       " 'hrqZyoLnJWAbb4e5QoamgT',\n",
       " 'bacDD1nRpeZcyoy0ts7ZqA',\n",
       " '0DdyYEpJbWNbQ0MHY0se20',\n",
       " '32jnMVPICzEjhkWQonRvw9']"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dfPlans['infa_id'].to_list()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
