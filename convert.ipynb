{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "import subprocess\n",
    "import uuid\n",
    "import csv\n",
    "import json\n",
    "import hashlib"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Read the Config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'name': 'tf_Example-1701471595480',\n",
       " 'sourceOrgId': '2lh8CM1r57OkWgGofQVMIk',\n",
       " 'sourceOrgName': 'Jon Bowring Suborg',\n",
       " 'exportedObjects': [{'objectGuid': 'aJDWwb7VFSmbzZ86glzi20',\n",
       "   'objectName': 'tf_Example',\n",
       "   'objectType': 'TASKFLOW',\n",
       "   'path': '/Explore/Default',\n",
       "   'metadata': {'modelVersion': {'major': 1, 'minor': 0},\n",
       "    'repoInfo': {'repoHandle': '3RKWa-gt-522578-2023-12-01T22:58:53.881Z::tf.xml'},\n",
       "    'objectRefs': ['1jY0fuy0iEUhkrHVLx78WK'],\n",
       "    'contextAttributes': None,\n",
       "    'additionalInfo': {'description': '',\n",
       "     'contentType': 'application/json; charset=utf-8',\n",
       "     'documentState': 'VALID'}}},\n",
       "  {'objectGuid': '92TQndHw9hvjJrQafpLX2R',\n",
       "   'objectName': 'Default',\n",
       "   'objectType': 'Project',\n",
       "   'path': '/Explore',\n",
       "   'metadata': {'modelVersion': {'major': 0, 'minor': 0},\n",
       "    'repoInfo': None,\n",
       "    'objectRefs': [],\n",
       "    'contextAttributes': [{'name': 'IS_DEF_LOC', 'value': 'true'}],\n",
       "    'additionalInfo': {'description': 'Auto-generated Default Project',\n",
       "     'contentType': None,\n",
       "     'documentState': 'COMPLETE'}}},\n",
       "  {'objectGuid': '1jY0fuy0iEUhkrHVLx78WK',\n",
       "   'objectName': 'mt_Example',\n",
       "   'objectType': 'MTT',\n",
       "   'path': '/Explore/Default',\n",
       "   'metadata': {'modelVersion': {'major': 0, 'minor': 0},\n",
       "    'repoInfo': {'repoHandle': '010SU10Z00000000001H'},\n",
       "    'objectRefs': [],\n",
       "    'contextAttributes': None,\n",
       "    'additionalInfo': {'description': '',\n",
       "     'contentType': 'JSON',\n",
       "     'documentState': 'VALID'}}}]}"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "with open('config/exportMetadata.v2.json', 'r') as infile:\n",
    "    exportMetadata = json.load(infile)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Read the plans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read the execution plans\n",
    "dfPlans = pd.read_csv('in/plans.csv', dtype='str', encoding='utf-8', na_filter=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['Echo Employee Snapshot Oracle R12.1.3'], dtype=object)"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Get a list of unique execution plans\n",
    "plans = dfPlans['plan_name'].unique()\n",
    "plans"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create the Import Packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For each unique plan\n",
    "for plan in plans:\n",
    "    \n",
    "    # Create IDs and a clean version of the name for the new taskflow\n",
    "    tName = re.sub(r'[^\\w\\d]+', '_', plan)\n",
    "    projectID = str(uuid.uuid4())\n",
    "    taskflowID = str(uuid.uuid4())\n",
    "    mapID = '1jY0fuy0iEUhkrHVLx78WK' # TODO Update to dynamically get the correct mapping\n",
    "\n",
    "    # Create the ContentsofExportPackage File\n",
    "    content = {'objectPath': ['/Explore/Default','/Explore'], 'objectName': [tName, 'Default'], 'objectType': ['TASKFLOW', 'Project'], 'id': [taskflowID, projectID]}\n",
    "    contentDf = pd.DataFrame(data=content)\n",
    "    contentDf.to_csv(f'out/ContentsofExportPackage_{tName}.csv', index=False, quoting=csv.QUOTE_NONE)\n",
    "\n",
    "    # Create the exportMetadata file\n",
    "    exportMetadata['name'] = tName\n",
    "    taskflowObj = list(filter(lambda x: x['objectType'] == 'TASKFLOW', exportMetadata['exportedObjects']))[0]\n",
    "    taskflowObj['objectGuid'] = taskflowID\n",
    "    taskflowObj['objectName'] = tName\n",
    "    taskflowObj['objectRefs'] = ['1jY0fuy0iEUhkrHVLx78WK'] # TODO Update to dynamically get the correct mapping\n",
    "    projectObj = list(filter(lambda x: x['objectType'] == 'Project', exportMetadata['exportedObjects']))[0]\n",
    "    projectObj['objectGuid'] = projectID\n",
    "    mappingObj = list(filter(lambda x: x['objectType'] == 'MTT', exportMetadata['exportedObjects']))[0]\n",
    "    mappingObj['objectGuid'] = '1jY0fuy0iEUhkrHVLx78WK' # TODO Update to dynamically get the correct mapping\n",
    "    mappingObj['objectName'] = 'mt_Example' # TODO Update to dynamically get the correct mapping\n",
    "    exportMetadata['exportedObjects'] = [taskflowObj, projectObj, mappingObj]\n",
    "    with open('out/exportMetadata.v2.json', 'w') as outfile:\n",
    "        outfile.write(json.dumps(exportMetadata))\n",
    "\n",
    "    # Run the XQuery conversion\n",
    "    console = subprocess.run([\"java\", \"-Xmx14000M\", \"-cp\", \"../saxon-he-10.5.jar\", \"net.sf.saxon.Query\", \"-q:convert.xq\", f\"-o:out/Explore/Default/{tName}.TASKFLOW.xml\", f\"tname={tName}\", f\"tflowid={taskflowID}\"], capture_output=True)\n",
    "    \n",
    "    # Create the exportPackage.chksum file\n",
    "    with open('out/Explore/Default.Project.json', 'rb') as infile:\n",
    "        infileBytes = infile.read()\n",
    "        defaultProjectJsonHash = hashlib.sha256(infileBytes).hexdigest().upper()\n",
    "\n",
    "    with open('out/exportMetadata.v2.json', 'rb') as infile:\n",
    "        infileBytes = infile.read()\n",
    "        exportMetadataHash = hashlib.sha256(infileBytes).hexdigest().upper()\n",
    "\n",
    "    with open(f'out/Explore/Default/{tName}.TASKFLOW.xml', 'rb') as infile:\n",
    "        infileBytes = infile.read()\n",
    "        taskflowHash = hashlib.sha256(infileBytes).hexdigest().upper()\n",
    "    \n",
    "    lines = ['#\\n', '#Fri Dec 01 22:59:59 UTC 2023\\n', f'Explore/Default.Project.json={defaultProjectJsonHash}\\n', f'exportMetadata.v2.json={exportMetadataHash}\\n', f'Explore/Default/tf_Example.TASKFLOW.xml={taskflowHash}\\n']\n",
    "    with open('out/exportPackage.chksum', 'w') as outfile:\n",
    "        outfile.writelines(lines)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
